{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soynlp 학습기반 토크나이저\n",
    "<hr>\n",
    "\n",
    "- 품사 태깅, 단어 토큰화 등을 지원하는 단어 토크나이저\n",
    "- 비지도 학습으로 단어 토큰화 ==> 데이터에 자주 등장하는 단어들을 단어로 분석\n",
    "- 내부적으로 단어 점수 표로 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('에이', 'Noun'), ('비식스', 'Noun'), ('이대', 'Modifier'), ('휘', 'Noun'), ('1월', 'Number'), ('최애', 'Noun'), ('돌', 'Noun'), ('기부', 'Noun'), ('요정', 'Noun'), ('이다', 'Adjective'), ('.', 'Punctuation')]\n",
      "[('에이', 'Noun'), ('비식스', 'Noun'), ('이대', 'Modifier'), ('휘', 'Noun'), ('1월', 'Number'), ('최애돌기부요정입니다', 'Foreign'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab, Okt\n",
    "\n",
    "tokenizer = Okt()\n",
    "sentence = '에이비식스 이대휘 1월 최애돌 기부 요정 입니다.'\n",
    "\n",
    "# 형태소 분석 시 매개변수 stem = True 설정\n",
    "print(tokenizer.pos('에이비식스 이대휘 1월 최애돌 기부 요정 입니다.', stem=True))\n",
    "print(tokenizer.pos('에이비식스이대휘1월최애돌기부요정입니다.'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토크나이저 사용시 미리 말뭉치 데이터셋으로 학습 후 사용 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 문서 : 30091개\n"
     ]
    }
   ],
   "source": [
    "filename = 'text_data.txt'\n",
    "basedir = '../DATA/'\n",
    "\n",
    "# 한개로 통합된 문서 데이터 정리\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "# 단어 추출\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "corpus = DoublespaceLineCorpus(basedir + filename)\n",
    "print(f\"훈련 데이터 문서 : {len(corpus)}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.124 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 착 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.622289706275464, right_branching_entropy=2.5450082135840475, left_accessor_variety=93, right_accessor_variety=62, leftside_frequency=1728, rightside_frequency=309)\n",
      "2. 잣 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.2193959751230814, right_branching_entropy=0.5175983740977871, left_accessor_variety=10, right_accessor_variety=2, leftside_frequency=50, rightside_frequency=0)\n",
      "3. 듣 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.4289771168342935, right_branching_entropy=1.5537238380955622, left_accessor_variety=44, right_accessor_variety=10, leftside_frequency=748, rightside_frequency=0)\n",
      "4. 흐 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.5544767540098614, right_branching_entropy=1.979207356186778, left_accessor_variety=74, right_accessor_variety=25, leftside_frequency=850, rightside_frequency=56)\n",
      "5. 밤 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.8512419457069833, right_branching_entropy=3.1159559900695317, left_accessor_variety=78, right_accessor_variety=83, leftside_frequency=730, rightside_frequency=113)\n",
      "6. 넝 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0.7749927584562633, right_branching_entropy=-0.0, left_accessor_variety=3, right_accessor_variety=1, leftside_frequency=25, rightside_frequency=0)\n",
      "7. 샷 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=1.0949797342037142, right_branching_entropy=1.7460929019843046, left_accessor_variety=4, right_accessor_variety=6, leftside_frequency=15, rightside_frequency=24)\n",
      "8. 두 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=4.0379734129141935, right_branching_entropy=4.541132416097675, left_accessor_variety=249, right_accessor_variety=364, leftside_frequency=3773, rightside_frequency=3019)\n",
      "9. 밟 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0.9380014260102469, right_branching_entropy=2.0094443607226027, left_accessor_variety=5, right_accessor_variety=9, leftside_frequency=156, rightside_frequency=0)\n",
      "10. 굉 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.9130509976409464, right_branching_entropy=0.14370507759932824, left_accessor_variety=29, right_accessor_variety=3, leftside_frequency=414, rightside_frequency=0)\n",
      "11. 을 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=5.290676413089728, right_branching_entropy=5.425005803779664, left_accessor_variety=927, right_accessor_variety=837, leftside_frequency=719, rightside_frequency=203217)\n",
      "12. 몇 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.5167121584359204, right_branching_entropy=3.1447118728825547, left_accessor_variety=54, right_accessor_variety=52, leftside_frequency=137, rightside_frequency=54)\n",
      "13. ㅎ : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=0, rightside_frequency=6)\n",
      "14. 펄 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=1.3199101094893373, right_branching_entropy=0.6931471805599453, left_accessor_variety=5, right_accessor_variety=2, leftside_frequency=20, rightside_frequency=0)\n",
      "15. 밴 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.4107654994134124, right_branching_entropy=0.5421350200808047, left_accessor_variety=39, right_accessor_variety=3, leftside_frequency=194, rightside_frequency=0)\n",
      "16. 튼 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=1.5351161272956984, right_branching_entropy=2.3466231148444896, left_accessor_variety=20, right_accessor_variety=40, leftside_frequency=60, rightside_frequency=396)\n",
      "17. 왕 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.3899641072375224, right_branching_entropy=3.5795122624287945, left_accessor_variety=105, right_accessor_variety=109, leftside_frequency=1083, rightside_frequency=1260)\n",
      "18. 걷 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.176927051936125, right_branching_entropy=1.7456604932489985, left_accessor_variety=53, right_accessor_variety=12, leftside_frequency=759, rightside_frequency=0)\n",
      "19. 태 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=4.457011068051519, right_branching_entropy=3.843425536065674, left_accessor_variety=193, right_accessor_variety=156, leftside_frequency=2805, rightside_frequency=1157)\n",
      "20. 옳 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.2652561202618875, right_branching_entropy=1.498342591291627, left_accessor_variety=16, right_accessor_variety=5, leftside_frequency=180, rightside_frequency=0)\n",
      "21. 쥘 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0.5982695885852573, right_branching_entropy=-0.0, left_accessor_variety=2, right_accessor_variety=1, leftside_frequency=0, rightside_frequency=5)\n",
      "22. 빼 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.6043359288277976, right_branching_entropy=2.4541323391827756, left_accessor_variety=39, right_accessor_variety=21, leftside_frequency=540, rightside_frequency=0)\n",
      "23. 돼 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=4.223507152140958, right_branching_entropy=4.135001523112267, left_accessor_variety=148, right_accessor_variety=279, leftside_frequency=436, rightside_frequency=3383)\n",
      "24. 하 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=4.0079081870895905, right_branching_entropy=3.5578947313454248, left_accessor_variety=438, right_accessor_variety=319, leftside_frequency=30656, rightside_frequency=2633)\n",
      "25. 낱 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=1.8130990180764117, right_branching_entropy=0.8548286398639261, left_accessor_variety=7, right_accessor_variety=3, leftside_frequency=30, rightside_frequency=0)\n",
      "26. 짝 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.684826813932726, right_branching_entropy=3.4967921975123164, left_accessor_variety=18, right_accessor_variety=70, leftside_frequency=107, rightside_frequency=588)\n",
      "27. 많 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.305250144898969, right_branching_entropy=1.6922125785248359, left_accessor_variety=137, right_accessor_variety=16, leftside_frequency=7362, rightside_frequency=0)\n",
      "28. 렁 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=0, rightside_frequency=15)\n",
      "29. 칭 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=2.924731100317594, right_branching_entropy=2.6702818980757215, left_accessor_variety=28, right_accessor_variety=54, leftside_frequency=314, rightside_frequency=519)\n",
      "30. 째 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=1.6497349798420191, right_branching_entropy=4.665645250676689, left_accessor_variety=21, right_accessor_variety=216, leftside_frequency=14, rightside_frequency=2227)\n",
      "31. 탄 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=3.8778700864797995, right_branching_entropy=3.5103845295065854, left_accessor_variety=115, right_accessor_variety=119, leftside_frequency=1604, rightside_frequency=742)\n",
      "32. 슴 : Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0.6365141682948128, right_branching_entropy=2.6173540473611863, left_accessor_variety=2, right_accessor_variety=20, leftside_frequency=11, rightside_frequency=132)\n"
     ]
    }
   ],
   "source": [
    "for idx, key in enumerate(word_score_table.keys()):\n",
    "    print(f\"{idx+1}. {key} : {word_score_table[key]}\")\n",
    "    if idx > 30: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07716779358040307, 0.11518621707955429)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table['바다를'].cohesion_forward, word_score_table['바다에'].cohesion_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "# 토큰으로 쪼개기 위한 L토큰 기준값\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "l_tokenizer = LTokenizer(scores=scores)\n",
    "l_tokenizer.tokenize('국제사회와 우리의 노력들로 범죄를 척결하자', flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('국제사회', 0, 4, 0.20075093164820862, 4),\n",
       "  ('와', 4, 5, 0.0, 1),\n",
       "  ('우리', 5, 7, 0.4698248708580068, 2),\n",
       "  ('의', 7, 8, 0.0, 1),\n",
       "  ('노력', 8, 10, 0.17947431781701445, 2),\n",
       "  ('들로', 10, 12, 0.0, 2),\n",
       "  ('범죄', 12, 14, 0.29525483304042177, 2),\n",
       "  ('를', 14, 15, 0.0, 1),\n",
       "  ('척결', 15, 17, 0.1326530612244898, 2),\n",
       "  ('하자', 17, 19, 0.0, 2)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 최대 점수 토크나이저\n",
    "# 띄어쓰기가 되지 않는 문장에서 점수가 높은 글자 시퀀스를 순차적으로 찾아내는 토크나이저\n",
    "# 띄어쓰기가 되어 있지 않는 문장을 넣어서 점수를 통해 토큰화 된 결과\n",
    "\n",
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_token = MaxScoreTokenizer(scores=scores)\n",
    "maxscore_token.tokenize('국제사회와우리의노력들로범죄를척결하자', flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "ㅋㅋㅠㅠ 영화ㅠㅠ감동적^^^^^^\n"
     ]
    }
   ],
   "source": [
    "## soynlp 를 이용한 반복되는 문자 정제\n",
    "# ㅋㅋ, ㅎㅎ 등의 이모티콘의 경우 불필요하게 연속되는 경우가 많음\n",
    "# 반복되는 것은 하나로 정규화\n",
    "\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "import string\n",
    "print(string.punctuation)\n",
    "\n",
    "print(emoticon_normalize('ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ큐ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ'), emoticon_normalize('영화ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ감동적^^^^^^'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install customized_konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "\n",
    "\n",
    "twitter = Twitter()\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The MeCab dictionary does not exist at \"/usr/local/lib/mecab/dic/mecab-ko-dic\". Is the dictionary correctly installed?\nYou can also try entering the dictionary path when initializing the Mecab class: \"Mecab('/some/dic/path')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/MeCab/__init__.py:137\u001b[0m, in \u001b[0;36mTagger.__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTagger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ee:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/konlpy/tag/_mecab.py:77\u001b[0m, in \u001b[0;36mMecab.__init__\u001b[0;34m(self, dicpath)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagger \u001b[38;5;241m=\u001b[39m \u001b[43mTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-d \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdicpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagset \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/data/tagset/mecab.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m utils\u001b[38;5;241m.\u001b[39minstallpath)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/MeCab/__init__.py:139\u001b[0m, in \u001b[0;36mTagger.__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ee:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_info(rawargs)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mee\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n----------------------------------------------------------\n\nFailed initializing MeCab. Please see the README for possible solutions:\n\n    https://github.com/SamuraiT/mecab-python3#common-issues\n\nIf you are still having trouble, please file an issue here, and include the\nERROR DETAILS below:\n\n    https://github.com/SamuraiT/mecab-python3/issues\n\nissueを英語で書く必要はありません。\n\n------------------- ERROR DETAILS ------------------------\narguments: -d /usr/local/lib/mecab/dic/mecab-ko-dic\ndefault dictionary path: None\n[ifs] no such file or directory: /usr/local/etc/mecabrc\n----------------------------------------------------------\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m c_mecab \u001b[38;5;241m=\u001b[39m \u001b[43mMecab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m c_mecab\u001b[38;5;241m.\u001b[39mmorphs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m은경이는 사무실로 갔습니다.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/konlpy/tag/_mecab.py:80\u001b[0m, in \u001b[0;36mMecab.__init__\u001b[0;34m(self, dicpath)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagset \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/data/tagset/mecab.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m utils\u001b[38;5;241m.\u001b[39minstallpath)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe MeCab dictionary does not exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Is the dictionary correctly installed?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYou can also try entering the dictionary path when initializing the Mecab class: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMecab(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m/some/dic/path\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m dicpath)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstall MeCab in order to use it: http://konlpy.org/en/latest/install/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: The MeCab dictionary does not exist at \"/usr/local/lib/mecab/dic/mecab-ko-dic\". Is the dictionary correctly installed?\nYou can also try entering the dictionary path when initializing the Mecab class: \"Mecab('/some/dic/path')\""
     ]
    }
   ],
   "source": [
    "\n",
    "c_mecab = Mecab()\n",
    "c_mecab.morphs('은경이는 사무실로 갔습니다.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
