{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchtext 라이브러리로 텍스트 분류\n",
    "<hr>\n",
    "\n",
    "- 1단계 : 데이터 전처리 : 숫자형식으로 변환하는 것 까지\n",
    "- 2단계 : 모델 구현\n",
    "\n",
    "- 1-1 데이터 준비 => 내장 데이터셋 활용\n",
    "    * AG_NEWS 데이터셋 반복자 : 레이블 (label) + 문장의 튜플(tuple) 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: NVIDIA_VISIBLE_DEVICES=MIG-da4f3553-5a31-5138-937b-a4a90f2ec139\n"
     ]
    }
   ],
   "source": [
    "%set_env NVIDIA_VISIBLE_DEVICES=MIG-da4f3553-5a31-5138-937b-a4a90f2ec139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "\n",
    "os.environ['NVIDIA_VISIBLE_DEVICES']='MIG-da4f3553-5a31-5138-937b-a4a90f2ec139'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "# ==> DataPipe 타입 >> iterator 타입 형변환\n",
    "train_iter = iter(AG_NEWS(split='train'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터 확인 => (label, text), label 1-4\n",
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (2) 데이터 처리 파이프라인 준비 \n",
    "\n",
    "<hr>\n",
    "\n",
    "* 어휘집(vocab), 단어 벡터(word vector), 토크나이저(tokenizer)\n",
    "* 가공되지 않은 텍스트 문자열에 대한 데이터 처리 빌딜 블록\n",
    "* 일반적인 NLP 데이터 처리\n",
    "    * 첫번째 단계 : 가공되지 않은 학습 데이터셋으로 어휘집 생성\n",
    "        => 토큰 목록 또는 반복자 받는 내장 팩토리 함수(factor function) : build_vocab_from_iterator\n",
    "    * 사용자는 어휘집에 추가할 특수 기호 전달 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "train_iter = AG_NEWS(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 제너레이터 함수 : 데이터 추출하여 토큰화\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        # 라벨, 텍스트  ---> 텍스트 토큰화\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "# 단어 사전 생성\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>'])\n",
    "\n",
    "## <UNK> 인덱스를 0번으로 지정\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1913, 229, 5297, 2238]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['<unk>','am', 'there', 'example', 'beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 ===> 정수 인코딩\n",
    "text_pipeline = lambda x : vocab(tokenizer(x))\n",
    "\n",
    "# 레이블 ===> 정수 인코딩\n",
    "label_pipeline = lambda x : int(x) - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 데이터 배치(batch)와 반복자 생성\n",
    "<hr>\n",
    "\n",
    "- torch.utils.data.DataLoader : getitem(), len(), 구현한 맵 형태(map-style)\n",
    "- collate_fn() : DataLoader 로부터 생성된 샘플 배치 함수\n",
    "    * 입력 : DataLoader에 배치 크기(batch size)가 있는 배치(Batch) 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def collate_batch(batch):\n",
    "    # 배치크기 만큼의 라벨, 텍스트, 오프셋 값 저장 변수\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "\n",
    "    # 1개씩 뉴스기사, 라벨 추출 해서 저장\n",
    "    for (_label, _text) in batch:\n",
    "        # 라벨 인코딩 후 저장\n",
    "        label_list.append(label_pipeline(_label))\n",
    "\n",
    "        # 텍스트 인코딩 후 저장\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "\n",
    "        # 텍스트 offset 즉, 텍스트 크기/길이 저장\n",
    "        offsets.append(processed_text.size(0))\n",
    "\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "dataloader = DataLoader(train_iter, batch_size=64, shuffle=False, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num class =  4 , vocab_size =  95811\n"
     ]
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('num class = ',num_class,', vocab_size = ' , vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([431, 425,   1,  ...,   1,   1,   1], device='cuda:0') tensor([   0,   29,   71,  111,  151,  194,  242,  289,  338,  426,  457,  501,\n",
      "         557,  588,  638,  692,  724,  750,  802,  834,  865,  894,  922,  944,\n",
      "         978, 1008, 1041, 1072, 1100, 1128, 1159, 1185, 1215, 1251, 1285, 1311,\n",
      "        1343, 1394, 1443, 1512, 1588, 1673, 1725, 1759, 1819, 1882, 1923, 1956,\n",
      "        1999, 2037, 2055, 2076, 2105, 2137, 2179, 2204, 2223, 2243, 2265, 2325,\n",
      "        2414, 2461, 2545, 2600], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for labels, texts, offsets in dataloader:\n",
    "    print(labels, texts, offsets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TextSentiment(nn.Module): \n",
    "    def __init__(self, vocab_size, embed_dim, num_class): \n",
    "        super(TextSentiment, self).__init__() \n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True) \n",
    "        self.fc = nn.Linear(embed_dim, num_class) \n",
    "        self.init_weights() \n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = TextSentiment(vocab_size, embed_dim, num_class)\n",
    "criterion = F.cross_entropy()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
